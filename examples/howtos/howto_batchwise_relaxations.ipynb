{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d100d71c",
   "metadata": {},
   "source": [
    "# Batch-wise Structure Relaxation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd51dfe1",
   "metadata": {},
   "source": [
    "In this tutorial, we show how to use the ``TorchStructureLBFGS``. It enables relaxation of structures in a batch-wise manner, i.e. it optimizes multiple structures in parallel. This is particularly useful, when many relatively similar structures (--> similar time until convergence) should be relaxed while requiring possibly short simulation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f71b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ase.io import read\n",
    "\n",
    "import schnetpack as spk\n",
    "from schnetpack import properties\n",
    "from schnetpack.interfaces.ase_interface import AtomsConverter\n",
    "from schnetpack.interfaces.batchwise_optimizer import TorchStructureLBFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6339e784",
   "metadata": {},
   "source": [
    "First, we load the force field model that provides the forces for the relaxation process. To avoids back-propagation through the graph multiple times, the response (forces) module is disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be235c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../../tests/testdata/md_ethanol.model\"\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# load model\n",
    "model = torch.load(model_path, map_location=device)\n",
    "\n",
    "# remove response modules (to avoid differentiating more than once)\n",
    "model.model_outputs = [\"energy\"]\n",
    "model.do_postprocessing = False\n",
    "model.required_derivatives = []\n",
    "model.output_modules = torch.nn.ModuleList([model.output_modules[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f87158",
   "metadata": {},
   "source": [
    "Subsequently, we load the batch of initial structures utilizing ASE (supports xyz, db and more) and convert it to SchNetPack input format. For this purpose we need use the ``AtomsConverter`` with suitable neighbor list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2602ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_structure_file = \"../../tests/testdata/md_ethanol.xyz\"\n",
    "\n",
    "# load initial structures\n",
    "ats = read(input_structure_file, index=\":\")\n",
    "\n",
    "# define neighbor list\n",
    "cutoff = model.representation.cutoff.item()\n",
    "nbh_list=spk.transform.MatScipyNeighborList(cutoff=cutoff)\n",
    "\n",
    "# build atoms converter\n",
    "atoms_converter = AtomsConverter(\n",
    "    neighbor_list=nbh_list,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# convert atoms object to schnetpack batch\n",
    "inputs = atoms_converter(ats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5323eaa6",
   "metadata": {},
   "source": [
    "For some systems it helps to fix the positions of certain atoms during the relaxation. This can be achieved by providing a mask of boolean entries to ``TorchStructureLBFGS``. The mask is a list of $3n_\\text{atoms}$ entries, i.e. it contains three entries for each atom associated with the respective directions in cartesian space. Here, we do not fix any atoms. Hence, the mask only contains ``True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e05da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define structure mask for optimization (True for fixed, False for non-fixed)\n",
    "n_atoms = len(ats[0].get_atomic_numbers())\n",
    "single_structure_mask = [False for _ in range(n_atoms * 3)]\n",
    "# expand mask by number of input structures (fixed atoms are equivalent for all input structures)\n",
    "mask = single_structure_mask * len(ats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b22e8",
   "metadata": {},
   "source": [
    "Finally, we run the optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e80e2433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:00<04:11,  3.96it/s]\n",
      "INFO:root:max. atomic force: 0.0003327234007883817\n"
     ]
    }
   ],
   "source": [
    "# Initialize optimizer\n",
    "optimizer = TorchStructureLBFGS(\n",
    "    model=model,\n",
    "    model_inputs=inputs,\n",
    "    fixed_atoms_mask=mask\n",
    ")\n",
    "\n",
    "# run optimization\n",
    "optimizer.run(fmax=0.0005, max_opt_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed93e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-4.9264,  1.5385, -0.0645],\n        [-3.4131,  1.4534, -0.1381],\n        [-5.2331,  2.2933,  0.6734],\n        [-5.3542,  0.5698,  0.2303],\n        [-5.3460,  1.8166, -1.0417],\n        [-2.9984,  1.1848,  0.8521],\n        [-2.9902,  2.4354, -0.4237],\n        [-3.0735,  0.4551, -1.1144],\n        [-2.1046,  0.3996, -1.1626]], device='cuda:0', requires_grad=True)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get new atomic positions\n",
    "optimizer.get_relaxed_structure()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
